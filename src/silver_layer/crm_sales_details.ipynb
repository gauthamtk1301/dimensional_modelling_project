{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affca13b-2228-4355-ba79-80e78cf4a25d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"\")\n",
    "dbutils.widgets.text(\"schema\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "spark.sql(f\"USE SCHEMA {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f5f954-dd10-46d8-9fa9-d918384fd58c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.schemaLocation\", \"/Volumes/gautham/gtk_scm/test_vlm/scm/crm_sales_details/\")   # ðŸ”¹ stores inferred schema here\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")                          # infer data types\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .option(\"cloudFiles.maxFilesPerTrigger\", 100)\n",
    "    .load(\"/Volumes/gautham/gtk_scm/test_vlm/src/crm_sales_details/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c653ebb-1c2b-43ae-a2b8-6b2b1520eb89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_batch(df, batch_id):\n",
    "    df=df.withColumn('sls_order_dt',expr(\"\"\"CASE \n",
    "\t\t\t\tWHEN sls_order_dt = 0 OR LEN(sls_order_dt) != 8 THEN NULL\n",
    "\t\t\t\tELSE to_date(CAST(sls_order_dt AS STRING), 'yyyyMMdd')\n",
    "\t\t\tEND\"\"\"))\n",
    "    df=df.withColumn('sls_ship_dt',expr(\"\"\"CASE \n",
    "                WHEN sls_ship_dt  = 0 OR LEN(sls_ship_dt ) != 8 THEN NULL\n",
    "                ELSE to_date(CAST(sls_ship_dt AS STRING), 'yyyyMMdd')\n",
    "            END\"\"\"))\n",
    "\n",
    "    df=df.withColumn('sls_due_dt',expr(\"\"\"CASE \n",
    "                WHEN sls_due_dt  = 0 OR LEN(sls_ship_dt ) != 8 THEN NULL\n",
    "                ELSE to_date(CAST(sls_ship_dt AS STRING), 'yyyyMMdd')\n",
    "            END\"\"\"))\n",
    "    df = df.withColumn(\n",
    "    \"sls_sales\",\n",
    "    when(\n",
    "        (col(\"sls_sales\").isNull()) | \n",
    "        (col(\"sls_sales\") <= 0) | \n",
    "        (col(\"sls_sales\") != col(\"sls_quantity\") * abs(col(\"sls_price\"))),\n",
    "        col(\"sls_quantity\") * abs(col(\"sls_price\"))\n",
    "    ).otherwise(col(\"sls_sales\"))\n",
    "    )\n",
    "\n",
    "    # Step 2: Recalculate sls_price (use the updated sls_sales)\n",
    "    df = df.withColumn(\n",
    "    \"sls_price\",\n",
    "    when(\n",
    "        (col(\"sls_price\").isNull()) | (col(\"sls_price\") <= 0),\n",
    "        when(col(\"sls_quantity\") == 0, lit(None))  # handle division by zero\n",
    "        .otherwise(col(\"sls_sales\") / col(\"sls_quantity\"))\n",
    "    ).otherwise(col(\"sls_price\"))\n",
    "    )\n",
    "\n",
    "\n",
    "    src_df=df.withcolumn('audit_checksum',xxhash64(concat(coalesce('sls_cust_id',lit('null')),\n",
    "                                                      coalesce('sls_order_dt',lit('null')),\n",
    "                                                      coalesce('sls_ship_dt',lit('null')),\n",
    "                                                      coalesce('sls_due_dt',lit('null')),\n",
    "                                                      coalesce('sls_sales',lit('null')),\n",
    "                                                      coalesce('sls_quantity'.cast(\"string\"),lit('null')),\n",
    "                                                      coalesce('sls_price'.cast(\"string\"),lit('null'))\n",
    "                                                     )\n",
    "                                                )\n",
    "                     ).withColumn('primary_key',concat('sls_ord_num','sls_prd_key'))\n",
    "    \n",
    "    \n",
    "    tgt_active_df=spark.sql(\"select concat(sls_ord_num,sls_ord_num) as primary_key,audit_checksum from crm_sales_details where active_flag='Y'\")    \n",
    "    \n",
    "    # ------------------------------\n",
    "    # Step 2: Left join source with active target on primary key\n",
    "    # ------------------------------\n",
    "    join_df = (\n",
    "        src_df.alias(\"src\")\n",
    "        .join(tgt_active_df.alias(\"tgt\"), on=\"primary_key\", how=\"left\")\n",
    "    )\n",
    "    \n",
    "    # ------------------------------\n",
    "    # Step 3: Drop completely same rows (no change)\n",
    "    # ------------------------------\n",
    "    # Rows where checksum is same => unchanged\n",
    "    changed_df = join_df.filter(\n",
    "        (F.col(\"tgt.audit_checksum\").isNull()) | \n",
    "        (F.col(\"src.audit_checksum\") != F.col(\"tgt.audit_checksum\"))\n",
    "    )\n",
    "    \n",
    "    # ------------------------------\n",
    "    # Step 4: Handle changed/new records\n",
    "    # ------------------------------\n",
    "    \n",
    "    # Separate new rows and changed rows\n",
    "    new_rows_df = changed_df.filter(F.col(\"tgt.primary_key\").isNull())\n",
    "    changed_existing_df = changed_df.filter(F.col(\"tgt.primary_key\").isNotNull())\n",
    "    \n",
    "    # Create the new version rows for changed records\n",
    "    new_version_rows = changed_existing_df.select(\n",
    "        \"src.*\"\n",
    "    ).withColumn(\"effective_start_date\", F.current_timestamp()) \\\n",
    "    .withColumn(\"effective_end_date\", F.lit(None).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"is_active\", F.lit(\"Y\"))\n",
    "    \n",
    "    # Old version rows need to be deactivated\n",
    "    old_version_rows = changed_existing_df.select(\"tgt.*\").withColumn(\"is_active\", F.lit(\"N\")) \\\n",
    "        .withColumn(\"effective_end_date\", F.current_timestamp())\n",
    "    \n",
    "    # Combine all three (new inserts + new version + old version)\n",
    "    final_merge_df = (\n",
    "        new_rows_df.select(\"src.*\").withColumn(\"merge_key\", F.col(\"src.primary_key\"))\n",
    "        .unionByName(\n",
    "            old_version_rows.withColumn(\"merge_key\", F.col(\"primary_key\"))\n",
    "        )\n",
    "        .unionByName(\n",
    "            new_version_rows.withColumn(\"merge_key\", F.lit(None))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ------------------------------\n",
    "    # Step 5: Perform MERGE in a single step\n",
    "    # ------------------------------\n",
    "    \n",
    "    from delta.tables import DeltaTable\n",
    "    \n",
    "    delta_tgt = DeltaTable.forName(spark, \"crm_sales_details\")\n",
    "    \n",
    "    (\n",
    "        delta_tgt.alias(\"tgt\")\n",
    "        .merge(\n",
    "            final_merge_df.alias(\"src\"),\n",
    "            \"concat(tgt.sls_ord_num,tgt.sls_ord_num) = src.merge_key\"\n",
    "        )\n",
    "        # update old record to inactive\n",
    "        .whenMatchedUpdate(set={\n",
    "            \"is_active\": \"'N'\",\n",
    "            \"effective_end_date\": \"current_timestamp()\"\n",
    "        })\n",
    "        # insert new or changed version\n",
    "        .whenNotMatchedInsert(values={\n",
    "            \"sls_ord_num\": \"src.sls_ord_num\",\n",
    "            \"sls_prd_key\": \"src.sls_prd_key\",\n",
    "            \"sls_cust_id\": \"src.sls_cust_id\",\n",
    "            \"sls_order_dt\": \"src.sls_order_dt\",\n",
    "            \"sls_ship_dt\": \"src.sls_ship_dt\",\n",
    "            \"sls_due_dt\": \"src.sls_due_dt\",\n",
    "            \"sls_sales\": \"src.sls_sales\",\n",
    "            \"sls_quantity\": \"src.sls_quantity\",\n",
    "            \"sls_price\": \"src.sls_price\",\n",
    "            \"dwh_create_date\": \"src.dwh_create_date\",\n",
    "            \"audit_checksum\": \"src.audit_checksum\",\n",
    "            \"is_active\": \"'Y'\",\n",
    "            \"effective_start_date\": \"current_timestamp()\",\n",
    "            \"effective_end_date\": \"NULL\"\n",
    "        })\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fed19c3-8875-4477-97f2-6f52ac912adb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream_df.writeStream.foreachBatch(process_batch).option(\"checkpointLocation\", \"/Volumes/gautham/gtk_scm/test_vlm/chkp/crm_sales_details/\").trigger(availableNow=True).start().awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5692888848956435,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "crm_sales_details",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
